# WeNet configuration for pronunciation assessment
# Based on LibriSpeech Conformer model

# Model
model: asr_model
model_conf:
  ctc_weight: 0.3
  lsm_weight: 0.1
  length_normalized_loss: false
  reverse_weight: 0.3

# Dataset
dataset: dataset
dataset_conf:
  filter_conf:
    max_length: 40960
    min_length: 10
    token_max_length: 200
    token_min_length: 1
  resample_conf:
    resample_rate: 16000
  speed_perturb: true
  spec_aug: true
  spec_aug_conf:
    num_t_mask: 2
    num_f_mask: 2
    max_t: 50
    max_f: 10
  shuffle: true
  shuffle_conf:
    shuffle_size: 1500
  sort: true
  sort_conf:
    sort_size: 500
  batch_conf:
    batch_type: static
    batch_size: 16
  num_workers: 4

# Input
input_dim: 80

# Conformer architecture
encoder: conformer
encoder_conf:
  output_size: 256
  attention_heads: 4
  linear_units: 2048
  num_blocks: 12
  dropout_rate: 0.1
  positional_dropout_rate: 0.1
  attention_dropout_rate: 0.1
  input_layer: conv2d
  normalize_before: true
  pos_enc_layer_type: rel_pos
  selfattention_layer_type: rel_selfattn
  activation_type: swish
  use_cnn_module: true
  cnn_module_kernel: 15
  cnn_module_norm: layer_norm
  causal: true
  use_dynamic_chunk: true
  use_dynamic_left_chunk: false

decoder: bitransformer
decoder_conf:
  attention_heads: 4
  linear_units: 2048
  num_blocks: 3
  dropout_rate: 0.1
  positional_dropout_rate: 0.1
  r_num_blocks: 3
  self_attention_dropout_rate: 0.1
  src_attention_dropout_rate: 0.1

# Training
optim: adam
optim_conf:
  lr: 0.002
scheduler: warmuplr
scheduler_conf:
  warmup_steps: 25000

# Output
output_dim: 5002 # Vocabulary size for LibriSpeech (from downloaded model)

# CTC
ctc_conf:
  ctc_blank_id: 0

# Alignment specific
alignment:
  frame_shift: 10 # ms
  frame_length: 25 # ms
  sample_rate: 16000
  use_attention_alignment: true
  attention_temperature: 1.0
